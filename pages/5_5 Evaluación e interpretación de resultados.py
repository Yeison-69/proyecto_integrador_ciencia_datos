import streamlit as st
from utils.carga_datos import cargar_datos_loteria
from utils.eda_helpers import *
from utils.graficos import *
import pandas as pd
from scipy import stats

st.title("üìà 5. Evaluaci√≥n e Interpretaci√≥n de Resultados")

st.markdown("""
## üéØ Objetivo de esta Etapa

Evaluar los hallazgos del an√°lisis exploratorio, realizar pruebas estad√≠sticas y generar insights accionables
basados en los datos hist√≥ricos de la loter√≠a.
""")

try:
    df = cargar_datos_loteria()
    
    # Tabs para organizar
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä M√©tricas Clave",
        "üî¨ Pruebas Estad√≠sticas",
        "üí° Insights",
        "üìã Interpretaci√≥n"
    ])
    
    # TAB 1: M√©tricas Clave
    with tab1:
        st.header("üìä M√©tricas Clave del An√°lisis")
        
        st.subheader("KPIs Principales")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "Cobertura Temporal",
                f"{df['a√±o'].nunique()} a√±os",
                delta=f"{df['a√±o'].min()}-{df['a√±o'].max()}"
            )
        
        with col2:
            completitud = (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
            st.metric(
                "Completitud",
                f"{completitud:.1f}%",
                delta="Excelente" if completitud > 95 else "Revisar"
            )
        
        with col3:
            numeros_unicos = df['n√∫mero'].nunique()
            st.metric(
                "N√∫meros √önicos",
                f"{numeros_unicos:,}",
                delta=f"{(numeros_unicos/10000*100):.1f}% del total"
            )
        
        with col4:
            series_unicas = df['serie'].nunique()
            st.metric(
                "Series √önicas",
                f"{series_unicas:,}",
                delta=f"{len(df)} sorteos"
            )
        
        st.subheader("Frecuencia de Sorteos")
        
        sorteos_a√±o = df.groupby('a√±o').size()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Promedio por A√±o", f"{sorteos_a√±o.mean():.1f}")
        
        with col2:
            st.metric("A√±o con M√°s Sorteos", f"{sorteos_a√±o.idxmax()} ({sorteos_a√±o.max()})")
        
        with col3:
            st.metric("A√±o con Menos Sorteos", f"{sorteos_a√±o.idxmin()} ({sorteos_a√±o.min()})")
        
        st.plotly_chart(grafico_evolucion_por_a√±o(df), use_container_width=True)
        
        st.subheader("Distribuci√≥n de N√∫meros y Series")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Estad√≠sticas de N√∫meros**")
            st.write(f"Media: {df['n√∫mero'].mean():.2f}")
            st.write(f"Mediana: {df['n√∫mero'].median():.0f}")
            st.write(f"Desv. Est√°ndar: {df['n√∫mero'].std():.2f}")
            st.write(f"Coef. Variaci√≥n: {(df['n√∫mero'].std()/df['n√∫mero'].mean()*100):.2f}%")
        
        with col2:
            st.write("**Estad√≠sticas de Series**")
            st.write(f"Media: {df['serie'].mean():.2f}")
            st.write(f"Mediana: {df['serie'].median():.0f}")
            st.write(f"Desv. Est√°ndar: {df['serie'].std():.2f}")
            st.write(f"Coef. Variaci√≥n: {(df['serie'].std()/df['serie'].mean()*100):.2f}%")
    
    # TAB 2: Pruebas Estad√≠sticas
    with tab2:
        st.header("üî¨ Pruebas Estad√≠sticas")
        
        st.subheader("1. Prueba de Uniformidad (Chi-cuadrado)")
        st.markdown("""
        Evaluamos si los n√∫meros ganadores siguen una distribuci√≥n uniforme (todos tienen la misma probabilidad).
        """)
        
        # Agrupar n√∫meros en bins para chi-cuadrado
        bins = 20
        observed, bin_edges = np.histogram(df['n√∫mero'], bins=bins, range=(0, 10000))
        expected = len(df) / bins
        
        chi2_stat, p_value = stats.chisquare(observed, f_exp=[expected]*bins)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Estad√≠stico œá¬≤", f"{chi2_stat:.2f}")
        
        with col2:
            st.metric("P-value", f"{p_value:.4f}")
        
        with col3:
            if p_value > 0.05:
                st.metric("Resultado", "Uniforme ‚úÖ")
            else:
                st.metric("Resultado", "No Uniforme ‚ö†Ô∏è")
        
        if p_value > 0.05:
            st.success(f"‚úÖ No se rechaza la hip√≥tesis de uniformidad (p-value = {p_value:.4f} > 0.05). Los n√∫meros parecen distribuirse uniformemente.")
        else:
            st.warning(f"‚ö†Ô∏è Se rechaza la hip√≥tesis de uniformidad (p-value = {p_value:.4f} < 0.05). Puede haber sesgos en la distribuci√≥n.")
        
        st.subheader("2. Prueba de Normalidad (Shapiro-Wilk)")
        
        # Tomar muestra si hay muchos datos
        muestra = df['n√∫mero'].sample(min(5000, len(df)))
        stat_shapiro, p_shapiro = stats.shapiro(muestra)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Estad√≠stico W", f"{stat_shapiro:.4f}")
        
        with col2:
            st.metric("P-value", f"{p_shapiro:.4f}")
        
        if p_shapiro > 0.05:
            st.info(f"Los n√∫meros siguen una distribuci√≥n normal (p-value = {p_shapiro:.4f})")
        else:
            st.info(f"Los n√∫meros NO siguen una distribuci√≥n normal (p-value = {p_shapiro:.4f})")
        
        st.subheader("3. Prueba de Independencia (Autocorrelaci√≥n)")
        
        # Calcular autocorrelaci√≥n lag-1
        numeros_array = df.sort_values('fecha')['n√∫mero'].values
        if len(numeros_array) > 1:
            autocorr = np.corrcoef(numeros_array[:-1], numeros_array[1:])[0, 1]
            
            st.metric("Autocorrelaci√≥n (lag-1)", f"{autocorr:.4f}")
            
            if abs(autocorr) < 0.1:
                st.success(f"‚úÖ Los sorteos parecen ser independientes (autocorrelaci√≥n ‚âà 0)")
            else:
                st.warning(f"‚ö†Ô∏è Posible dependencia entre sorteos consecutivos")
        
        st.subheader("4. An√°lisis de Pares vs Impares")
        
        pares = (df['numero_par'] == 1).sum()
        impares = (df['numero_par'] == 0).sum()
        
        # Prueba binomial
        p_pares = pares / len(df)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("N√∫meros Pares", f"{pares} ({p_pares*100:.1f}%)")
        
        with col2:
            st.metric("N√∫meros Impares", f"{impares} ({(1-p_pares)*100:.1f}%)")
        
        with col3:
            diferencia = abs(p_pares - 0.5) * 100
            st.metric("Diferencia del 50%", f"{diferencia:.1f}%")
        
        if abs(p_pares - 0.5) < 0.05:
            st.success("‚úÖ La proporci√≥n de pares e impares es aproximadamente 50-50")
        else:
            st.info(f"‚ÑπÔ∏è Hay un ligero sesgo hacia n√∫meros {'pares' if p_pares > 0.5 else 'impares'}")
    
    # TAB 3: Insights
    with tab3:
        st.header("üí° Insights Principales")
        
        st.subheader("üé≤ Sobre los N√∫meros Ganadores")
        
        numero_mas_frecuente = df['n√∫mero'].mode()[0]
        frecuencia_max = (df['n√∫mero'] == numero_mas_frecuente).sum()
        
        st.markdown(f"""
        1. **N√∫mero m√°s frecuente**: {numero_mas_frecuente:04d} (apareci√≥ {frecuencia_max} veces)
        2. **Diversidad**: {df['n√∫mero'].nunique():,} n√∫meros √∫nicos de 10,000 posibles ({df['n√∫mero'].nunique()/10000*100:.1f}%)
        3. **Distribuci√≥n**: {'Aproximadamente uniforme' if p_value > 0.05 else 'Con algunos sesgos'}
        4. **Pares vs Impares**: {pares} pares ({p_pares*100:.1f}%) vs {impares} impares ({(1-p_pares)*100:.1f}%)
        """)
        
        st.subheader("üé´ Sobre las Series")
        
        serie_mas_frecuente = df['serie'].mode()[0]
        frecuencia_serie = (df['serie'] == serie_mas_frecuente).sum()
        
        st.markdown(f"""
        1. **Serie m√°s frecuente**: {serie_mas_frecuente} (apareci√≥ {frecuencia_serie} veces)
        2. **Diversidad**: {df['serie'].nunique():,} series √∫nicas
        3. **Rango**: {df['serie'].min()} a {df['serie'].max()}
        4. **Promedio**: {df['serie'].mean():.0f}
        """)
        
        st.subheader("üìÖ Sobre los Patrones Temporales")
        
        dia_mas_comun = df['dia_semana_nombre'].mode()[0]
        sorteos_dia = (df['dia_semana_nombre'] == dia_mas_comun).sum()
        
        mes_mas_comun = df['mes_nombre'].mode()[0]
        sorteos_mes = (df['mes_nombre'] == mes_mas_comun).sum()
        
        st.markdown(f"""
        1. **D√≠a m√°s com√∫n**: {dia_mas_comun} ({sorteos_dia} sorteos)
        2. **Mes m√°s com√∫n**: {mes_mas_comun} ({sorteos_mes} sorteos)
        3. **Frecuencia promedio**: {sorteos_a√±o.mean():.1f} sorteos por a√±o
        4. **Tendencia**: {'Creciente' if df.groupby('a√±o').size().corr(pd.Series(range(len(sorteos_a√±o)))) > 0 else 'Decreciente'} en el tiempo
        """)
        
        st.subheader("üî¢ Sobre los D√≠gitos")
        
        primer_digito_comun = df['primer_digito'].mode()[0]
        ultimo_digito_comun = df['ultimo_digito'].mode()[0]
        
        st.markdown(f"""
        1. **Primer d√≠gito m√°s com√∫n**: {primer_digito_comun}
        2. **√öltimo d√≠gito m√°s com√∫n**: {ultimo_digito_comun}
        3. **Suma promedio de d√≠gitos**: {df['suma_digitos'].mean():.1f}
        """)
    
    # TAB 4: Interpretaci√≥n
    with tab4:
        st.header("üìã Interpretaci√≥n General")
        
        st.markdown(f"""
        ## Resumen Ejecutivo
        
        Basado en el an√°lisis de **{len(df):,} sorteos** realizados entre **{df['a√±o'].min()}** y **{df['a√±o'].max()}**:
        
        ### ‚úÖ Validaci√≥n de Aleatoriedad
        
        - Los datos sugieren un sistema de sorteo {'razonablemente aleatorio' if p_value > 0.05 else 'con algunos patrones no aleatorios'}
        - La distribuci√≥n de n√∫meros es {'aproximadamente uniforme' if p_value > 0.05 else 'no completamente uniforme'}
        - Los sorteos parecen ser {'independientes' if abs(autocorr) < 0.1 else 'potencialmente dependientes'} entre s√≠
        
        ### üìä Caracter√≠sticas del Dataset
        
        - **Completitud**: {completitud:.1f}% - Excelente calidad de datos
        - **Cobertura**: {df['a√±o'].nunique()} a√±os de historia
        - **Diversidad**: {df['n√∫mero'].nunique():,} n√∫meros √∫nicos ({df['n√∫mero'].nunique()/10000*100:.1f}% del espacio posible)
        
        ### üéØ Implicaciones
        
        1. **Para jugadores**: No hay evidencia de patrones predecibles que puedan explotarse
        2. **Para analistas**: El dataset es robusto y adecuado para an√°lisis estad√≠stico
        3. **Para el sistema**: Los resultados sugieren un mecanismo de sorteo justo
        
        ### ‚ö†Ô∏è Limitaciones
        
        - El an√°lisis es descriptivo, no predictivo
        - Los patrones hist√≥ricos no garantizan resultados futuros
        - La aleatoriedad perfecta es imposible de probar definitivamente
        
        ### üí° Recomendaciones
        
        1. Continuar monitoreando la distribuci√≥n de n√∫meros en el tiempo
        2. Realizar auditor√≠as peri√≥dicas de aleatoriedad
        3. Mantener la transparencia en los procesos de sorteo
        4. Usar estos datos para educaci√≥n sobre probabilidad y estad√≠stica
        """)
        
        st.info("""
        **Nota Importante**: Este an√°lisis tiene fines educativos y estad√≠sticos. 
        La loter√≠a es un juego de azar y ning√∫n an√°lisis puede predecir resultados futuros.
        """)
    
    st.markdown("---")
    st.success("‚úÖ Etapa 5 completada. Procede a la siguiente secci√≥n: Comunicaci√≥n de Resultados.")

except Exception as e:
    st.error(f"‚ùå Error en la evaluaci√≥n: {e}")
    import traceback
    with st.expander("Ver detalles del error"):
        st.code(traceback.format_exc())
