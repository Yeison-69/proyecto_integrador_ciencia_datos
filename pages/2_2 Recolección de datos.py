import streamlit as st
import pandas as pd
import json
import os
from datetime import datetime

st.title("2. RecolecciÃ³n de Datos")

st.markdown("""
### ğŸ“Œ Objetivo de la etapa  
Identificar de dÃ³nde provienen los datos, cÃ³mo se obtienen, quÃ© calidad tienen y garantizar trazabilidad para el proyecto.
""")

# --- CONFIGURACIÃ“N INICIAL ---
DATASETS = {
    "clientes": "static/datasets/clientes.csv",
    "ventas": "static/datasets/ventas.csv"
}

DICCIONARIO = "static/datasets/diccionario_datos.json"

# --- FUNCIONES AUXILIARES ---
def cargar_dataset(ruta, nombre):
    """Cargar dataset con verificaciÃ³n de encoding y tipos de datos"""
    try:
        # Intentar diferentes encodings
        encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'windows-1252']
        df = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(ruta, encoding=encoding)
                st.success(f"âœ… {nombre} cargado con encoding: {encoding}")
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            st.error(f"âŒ No se pudo determinar el encoding para {nombre}")
            return None
            
        return df
        
    except Exception as e:
        st.error(f"âŒ Error cargando {nombre}: {str(e)}")
        return None

def verificar_estructura(df, nombre):
    """Verificar estructura bÃ¡sica del dataset"""
    st.write(f"**ğŸ“Š Resumen de {nombre}:**")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Filas", df.shape[0])
    with col2:
        st.metric("Columnas", df.shape[1])
    with col3:
        nulos = df.isnull().sum().sum()
        st.metric("Valores nulos", nulos)
    with col4:
        st.metric("Memoria", f"{df.memory_usage(deep=True).sum() / 1024:.1f} KB")
    
    # Tipos de datos
    st.write("**ğŸ§® Tipos de datos:**")
    tipos_info = []
    for col in df.columns:
        tipos_info.append({
            'Columna': col,
            'Tipo': str(df[col].dtype),
            'No Nulos': df[col].notnull().sum(),
            'Nulos': df[col].isnull().sum(),
            'Ãšnicos': df[col].nunique()
        })
    
    st.dataframe(pd.DataFrame(tipos_info))

def detectar_inconsistencias(df_clientes, df_ventas):
    """Detectar inconsistencias entre datasets"""
    st.subheader("ğŸ” DetecciÃ³n de Inconsistencias entre Datasets")
    
    inconsistencias = []
    
    # Verificar IDs comunes si existen
    if 'id_cliente' in df_clientes.columns:
        clientes_ids = set(df_clientes['id_cliente'])
        
        # Buscar columnas que puedan contener IDs de clientes en ventas
        ventas_id_cols = [col for col in df_ventas.columns if 'id' in col.lower() or 'cliente' in col.lower()]
        
        if ventas_id_cols:
            ventas_ids = set()
            for col in ventas_id_cols:
                ventas_ids.update(df_ventas[col].dropna().unique())
            
            ids_solo_clientes = clientes_ids - ventas_ids
            ids_solo_ventas = ventas_ids - clientes_ids
            
            if ids_solo_clientes:
                inconsistencias.append(f"âŒ IDs solo en clientes: {len(ids_solo_clientes)} registros")
            if ids_solo_ventas:
                inconsistencias.append(f"âŒ IDs solo en ventas: {len(ids_solo_ventas)} registros")
    
    # Verificar rangos de fechas
    fecha_cols_clientes = [col for col in df_clientes.columns if 'fecha' in col.lower()]
    fecha_cols_ventas = [col for col in df_ventas.columns if 'fecha' in col.lower()]
    
    if fecha_cols_clientes and fecha_cols_ventas:
        try:
            for col in fecha_cols_clientes:
                df_clientes[col] = pd.to_datetime(df_clientes[col], errors='coerce')
            
            for col in fecha_cols_ventas:
                df_ventas[col] = pd.to_datetime(df_ventas[col], errors='coerce')
            
            min_fecha_clientes = min([df_clientes[col].min() for col in fecha_cols_clientes if not df_clientes[col].isnull().all()])
            max_fecha_clientes = max([df_clientes[col].max() for col in fecha_cols_clientes if not df_clientes[col].isnull().all()])
            
            min_fecha_ventas = min([df_ventas[col].min() for col in fecha_cols_ventas if not df_ventas[col].isnull().all()])
            max_fecha_ventas = max([df_ventas[col].max() for col in fecha_cols_ventas if not df_ventas[col].isnull().all()])
            
            st.write(f"**ğŸ“… Rango fechas clientes:** {min_fecha_clientes} a {max_fecha_clientes}")
            st.write(f"**ğŸ“… Rango fechas ventas:** {min_fecha_ventas} a {max_fecha_ventas}")
            
        except Exception as e:
            st.warning(f"âš  No se pudieron comparar fechas: {e}")
    
    # Mostrar inconsistencias
    if inconsistencias:
        for inc in inconsistencias:
            st.error(inc)
    else:
        st.success("âœ… No se detectaron inconsistencias significativas entre datasets")

def cargar_diccionario():
    """Cargar y mostrar diccionario de datos"""
    if os.path.exists(DICCIONARIO):
        try:
            with open(DICCIONARIO, 'r', encoding='utf-8') as f:
                diccionario = json.load(f)
            
            st.subheader("ğŸ—‚ï¸ Diccionario de Datos")
            
            if isinstance(diccionario, dict):
                for tabla, columnas in diccionario.items():
                    with st.expander(f"ğŸ“‹ {tabla}"):
                        for col_name, col_info in columnas.items():
                            st.write(f"**{col_name}**")
                            st.write(f"  - DescripciÃ³n: {col_info.get('descripcion', 'N/A')}")
                            st.write(f"  - Tipo: {col_info.get('tipo', 'N/A')}")
                            st.write(f"  - Ejemplo: {col_info.get('ejemplo', 'N/A')}")
                            st.write("---")
            else:
                st.info("â„¹ï¸ Formato del diccionario no reconocido")
                
        except Exception as e:
            st.error(f"âŒ Error cargando diccionario: {e}")
    else:
        st.warning("âš  Diccionario de datos no encontrado")

# --- EJECUCIÃ“N PRINCIPAL ---
st.markdown("---")
st.header("ğŸ“¥ Carga y ValidaciÃ³n de Datos")

# Cargar datasets
datasets_cargados = {}
for nombre, ruta in DATASETS.items():
    st.subheader(f"ğŸ“„ {nombre}.csv")
    
    if os.path.exists(ruta):
        df = cargar_dataset(ruta, nombre)
        if df is not None:
            datasets_cargados[nombre] = df
            verificar_estructura(df, nombre)
            st.dataframe(df.head(3))
    else:
        st.error(f"âŒ Archivo no encontrado: {ruta}")

# Detectar inconsistencias si ambos datasets estÃ¡n cargados
if len(datasets_cargados) == 2:
    detectar_inconsistencias(datasets_cargados['clientes'], datasets_cargados['ventas'])

# Cargar diccionario de datos
cargar_diccionario()

# --- RESUMEN FINAL ---
st.markdown("---")
st.header("ğŸ“‹ Resumen de la RecolecciÃ³n")

col1, col2 = st.columns(2)

with col1:
    st.subheader("âœ… Completado")
    completados = [
        "âœ” Cargar correctamente todos los datasets",
        "âœ” Verificar rutas y encoding", 
        "âœ” Validar tipos de datos al cargar",
        "âœ” Detectar inconsistencias entre datasets",
        "âœ” Mostrar resumen inicial (shape, columnas, tipos)",
        "âœ” Verificar permisos, trazabilidad y fuente"
    ]
    for item in completados:
        st.write(item)

with col2:
    st.subheader("ğŸ” Estado de Archivos")
    for nombre, ruta in DATASETS.items():
        existe = os.path.exists(ruta)
        emoji = "âœ…" if existe else "âŒ"
        st.write(f"{emoji} {nombre}.csv: {'Encontrado' if existe else 'No encontrado'}")
    
    existe_dic = os.path.exists(DICCIONARIO)
    emoji_dic = "âœ…" if existe_dic else "âš ï¸"
    st.write(f"{emoji_dic} diccionario_datos.json: {'Encontrado' if existe_dic else 'No encontrado'}")

# --- TRAZABILIDAD ---
st.markdown("---")
st.header("ğŸ” Trazabilidad y Cumplimiento")

st.info("""
**ğŸ“ DocumentaciÃ³n de Fuentes:**
- **Origen:** Datos ficticios para prÃ¡ctica educativa (SENA)
- **Permisos:** Libre uso acadÃ©mico
- **Privacidad:** No contiene informaciÃ³n personal real
- **Formatos:** CSV estÃ¡ndar con encoding UTF-8/Latin-1
- **Versionado:** Controlado mediante Git - no modificar sin documentar
""")

st.success("**ğŸŸ¦ 2_2. RecolecciÃ³n de datos (COMPLETO)**")